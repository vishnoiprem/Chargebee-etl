{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cheil-test-review.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUyk/69ZhknHSAYZ7lpzBS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnoiprem/Chargebee-etl/blob/master/cheil_test_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ziqaqgdLKV9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tvmJPzRtMRqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K2MBTo2kMSJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.\tProblem:\n",
        "# How to unzip large .gz file (30 GB) effectively \n",
        "# a/ How to approach the problem.\n",
        "# b/ Any alternative solutions in case resources are limited.\n"
      ],
      "metadata": {
        "id": "q9svqxhSMX6k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mlkp3Q7GMb8-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tProblem:\n",
        "How to unzip large .gz file (30 GB) effectively \n",
        "a/ How to approach the problem.\n",
        "b/ Any alternative solutions in case resources are limited.\n",
        "`bold text`"
      ],
      "metadata": {
        "id": "yn0zJPHCMeha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WfiCwdHwMdqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we use the gzip < file > file.gz\n",
        "\n",
        "!touch cheil_1.txt\n",
        "!zip cheil_1.txt cheil_1.gz\n",
        "!gzip cheil_1.gz cheil_see.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BlThqbfMi_r",
        "outputId": "5835c87d-63cc-4bf8-be4a-01e30c524715"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: missing end signature--probably not a zip file (did you\n",
            "\tzip warning: remember to use binary mode when you transferred it?)\n",
            "\tzip warning: (if you are trying to read a damaged archive try -F)\n",
            "\n",
            "zip error: Zip file structure invalid (cheil_1.txt)\n",
            "gzip: cheil_1.gz already has .gz suffix -- unchanged\n",
            "gzip: cheil_see.txt: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITbnxujVMs1H",
        "outputId": "96994632-caf1-4652-fc38-8a7eb16cfdf1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Jul  6 13:22 sample_data\n",
            "-rw-r--r-- 1 root root   30 Jul 11 07:45 cheil.zip.gz\n",
            "-rw-r--r-- 1 root root    0 Jul 11 07:45 cheil.zip\n",
            "-rw-r--r-- 1 root root    0 Jul 11 07:48 cheil.gz\n",
            "-rw-r--r-- 1 root root    0 Jul 11 07:48 cheil_1.gz\n",
            "-rw-r--r-- 1 root root    0 Jul 11 07:49 cheil_1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz_qDScdOQP9",
        "outputId": "a5f429cc-e8cf-414a-97ca-97807d22a932"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Jul  6 13:22 sample_data\n",
            "-rw-r--r-- 1 root root   30 Jul 11 07:45 cheil.zip.gz\n",
            "-rw-r--r-- 1 root root    0 Jul 11 07:45 cheil.zip\n",
            "-rw-r--r-- 1 root root    0 Jul 11 07:48 cheil.gz\n",
            "-rw-r--r-- 1 root root    0 Jul 11 07:48 cheil_1.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.reddit.com/r/dataengineering/comments/ea0ka1/processing_large_gz_files_efficiently/"
      ],
      "metadata": {
        "id": "7ftegzJrOxhD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This sounds like a pretty good use case for Spark.\n",
        "\n",
        "# Drop the data on Azure Blob Storage in its compressed form\n",
        "\n",
        "# Get Azure Databricks setup\n",
        "\n",
        "# Query directly against the gzip files\n",
        "\n",
        "# Or ingest all of the data into a delta table\n",
        "\n",
        "# Query against the data with spark or, if you prefer, export to somewhere else."
      ],
      "metadata": {
        "id": "CZ1WBQE3PGI_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aYr_po3RPQ6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tWe want to get data from Adobe Analytics/SEMrush using API method, and put data into BigQuery (or any cloud databases) on a regular basis.\n",
        "\n",
        "```\n",
        "# This isa/ How to approach the problem? (i.e. how to proceed, research, …)\n",
        "b/ What factors need to be considered? (Performance wise, scalability wise …)\n",
        "c/ How to validate data (i.e. make sure source and target’s numbers match)\n",
        " formatted as code\n",
        "```\n",
        "\n",
        "bold text"
      ],
      "metadata": {
        "id": "4QrHGnB0PUl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GhxlSpHqPXG8"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}